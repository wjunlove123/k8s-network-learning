date
Thu 18 May 2023 04:49:30 PM CST

# node info: 192.168.2.66

# create a cluster with the local registry enabled in containerd
cat <<EOF | kind create cluster --name=cluster1 --image=192.168.2.100:5000/kindest/node:v1.23.4 --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
        disableDefaultCNI: true
        podSubnet: "10.10.0.0/16"
        serviceSubnet: "10.11.0.0/16"

nodes:
        - role: control-plane
        - role: worker


containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."192.168.2.100:5000"]
    endpoint = ["http://192.168.2.100:5000"]
EOF
Creating cluster "cluster1" ...
 â€¢ Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) ğŸ–¼  ...
 âœ“ Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) ğŸ–¼
 â€¢ Preparing nodes ğŸ“¦ ğŸ“¦   ...
 âœ“ Preparing nodes ğŸ“¦ ğŸ“¦ 
 â€¢ Writing configuration ğŸ“œ  ...
 âœ“ Writing configuration ğŸ“œ
 â€¢ Starting control-plane ğŸ•¹ï¸  ...
 âœ“ Starting control-plane ğŸ•¹ï¸
 â€¢ Installing StorageClass ğŸ’¾  ...
 âœ“ Installing StorageClass ğŸ’¾
 â€¢ Joining worker nodes ğŸšœ  ...
 âœ“ Joining worker nodes ğŸšœ
Set kubectl context to "kind-cluster1"
You can now use your cluster with:

kubectl cluster-info --context kind-cluster1

Thanks for using kind! ğŸ˜Š

# prep the environment
controller_node=$(kubectl get nodes --no-headers  -o custom-columns=NAME:.metadata.name| grep control-plane)
kubectl taint nodes $controller_node node-role.kubernetes.io/master:NoSchedule-
node/cluster1-control-plane untainted
kubectl get nodes -owide 
NAME                     STATUS     ROLES                  AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION      CONTAINER-RUNTIME
cluster1-control-plane   NotReady   control-plane,master   36s   v1.23.4   172.18.0.3    <none>        Ubuntu 21.10   5.15.0-71-generic   containerd://1.5.10
cluster1-worker          NotReady   <none>                 0s    v1.23.4   172.18.0.2    <none>        Ubuntu 21.10   5.15.0-71-generic   containerd://1.5.10
kubectl get pods -owide -A
NAMESPACE            NAME                                             READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
kube-system          coredns-64897985d-6hvlk                          0/1     Pending   0          18s   <none>       <none>                   <none>           <none>
kube-system          coredns-64897985d-jgpqb                          0/1     Pending   0          18s   <none>       <none>                   <none>           <none>
kube-system          etcd-cluster1-control-plane                      1/1     Running   0          35s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-apiserver-cluster1-control-plane            1/1     Running   0          35s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-controller-manager-cluster1-control-plane   1/1     Running   0          35s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-proxy-2p2x8                                 1/1     Running   0          18s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-proxy-6lz92                                 0/1     Pending   0          0s    <none>       cluster1-worker          <none>           <none>
kube-system          kube-scheduler-cluster1-control-plane            1/1     Running   0          33s   172.18.0.3   cluster1-control-plane   <none>           <none>
local-path-storage   local-path-provisioner-5ddd94ff66-fgqmh          0/1     Pending   0          18s   <none>       <none>                   <none>           <none>

# install CNI
cilium install --context kind-cluster1 --version v1.12.0 --helm-set ipam.mode=kubernetes,cluster.name=cluster1,cluster.id=1
ğŸ”® Auto-detected Kubernetes kind: kind
âœ¨ Running "kind" validation checks
âœ… Detected kind version "0.14.0"
â„¹ï¸  Using Cilium version 1.12.0
ğŸ”® Auto-detected cluster name: kind-cluster1
ğŸ”® Auto-detected datapath mode: tunnel
â„¹ï¸  helm template --namespace kube-system cilium cilium/cilium --version 1.12.0 --set cluster.id=1,cluster.name=cluster1,encryption.nodeEncryption=false,ipam.mode=kubernetes,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator,tunnel=vxlan
â„¹ï¸  Storing helm values file in kube-system/cilium-cli-helm-values Secret
ğŸ”‘ Created CA in secret cilium-ca
ğŸ”‘ Generating certificates for Hubble...
ğŸš€ Creating Service accounts...
ğŸš€ Creating Cluster roles...
ğŸš€ Creating ConfigMap for Cilium version 1.12.0...
ğŸš€ Creating Agent DaemonSet...
ğŸš€ Creating Operator Deployment...
âŒ› Waiting for Cilium to be installed and ready...
âœ… Cilium was successfully installed! Run 'cilium status' to view installation health
cilium status  --context kind-cluster1 --wait
[33m    /Â¯Â¯\
[36m /Â¯Â¯[33m\__/[32mÂ¯Â¯\[0m    Cilium:         [32mOK[0m
[36m \__[31m/Â¯Â¯\[32m__/[0m    Operator:       [32mOK[0m
[32m /Â¯Â¯[31m\__/[35mÂ¯Â¯\[0m    Hubble:         [36mdisabled[0m
[32m \__[34m/Â¯Â¯\[35m__/[0m    ClusterMesh:    [36mdisabled[0m
[34m    \__/
[0m
Deployment        cilium-operator    Desired: 1, Ready: [32m1/1[0m, Available: [32m1/1[0m
DaemonSet         cilium             Desired: 2, Ready: [32m2/2[0m, Available: [32m2/2[0m
Containers:       cilium             Running: [32m2[0m
                  cilium-operator    Running: [32m1[0m
Cluster Pods:     3/3 managed by Cilium
Image versions    cilium-operator    quay.io/cilium/operator-generic:v1.12.0@sha256:bb2a42eda766e5d4a87ee8a5433f089db81b72dd04acf6b59fcbb445a95f9410: 1
                  cilium             quay.io/cilium/cilium:v1.12.0@sha256:079baa4fa1b9fe638f96084f4e0297c84dd4fb215d29d2321dcbe54273f63ade: 2

