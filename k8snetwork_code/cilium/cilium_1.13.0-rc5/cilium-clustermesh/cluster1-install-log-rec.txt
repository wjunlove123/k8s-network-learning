date
Thu 18 May 2023 04:49:30 PM CST

# node info: 192.168.2.66

# create a cluster with the local registry enabled in containerd
cat <<EOF | kind create cluster --name=cluster1 --image=192.168.2.100:5000/kindest/node:v1.23.4 --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
        disableDefaultCNI: true
        podSubnet: "10.10.0.0/16"
        serviceSubnet: "10.11.0.0/16"

nodes:
        - role: control-plane
        - role: worker


containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."192.168.2.100:5000"]
    endpoint = ["http://192.168.2.100:5000"]
EOF
Creating cluster "cluster1" ...
 • Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) 🖼  ...
 ✓ Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) 🖼
 • Preparing nodes 📦 📦   ...
 ✓ Preparing nodes 📦 📦 
 • Writing configuration 📜  ...
 ✓ Writing configuration 📜
 • Starting control-plane 🕹️  ...
 ✓ Starting control-plane 🕹️
 • Installing StorageClass 💾  ...
 ✓ Installing StorageClass 💾
 • Joining worker nodes 🚜  ...
 ✓ Joining worker nodes 🚜
Set kubectl context to "kind-cluster1"
You can now use your cluster with:

kubectl cluster-info --context kind-cluster1

Thanks for using kind! 😊

# prep the environment
controller_node=$(kubectl get nodes --no-headers  -o custom-columns=NAME:.metadata.name| grep control-plane)
kubectl taint nodes $controller_node node-role.kubernetes.io/master:NoSchedule-
node/cluster1-control-plane untainted
kubectl get nodes -owide 
NAME                     STATUS     ROLES                  AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION      CONTAINER-RUNTIME
cluster1-control-plane   NotReady   control-plane,master   36s   v1.23.4   172.18.0.3    <none>        Ubuntu 21.10   5.15.0-71-generic   containerd://1.5.10
cluster1-worker          NotReady   <none>                 0s    v1.23.4   172.18.0.2    <none>        Ubuntu 21.10   5.15.0-71-generic   containerd://1.5.10
kubectl get pods -owide -A
NAMESPACE            NAME                                             READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
kube-system          coredns-64897985d-6hvlk                          0/1     Pending   0          18s   <none>       <none>                   <none>           <none>
kube-system          coredns-64897985d-jgpqb                          0/1     Pending   0          18s   <none>       <none>                   <none>           <none>
kube-system          etcd-cluster1-control-plane                      1/1     Running   0          35s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-apiserver-cluster1-control-plane            1/1     Running   0          35s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-controller-manager-cluster1-control-plane   1/1     Running   0          35s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-proxy-2p2x8                                 1/1     Running   0          18s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-proxy-6lz92                                 0/1     Pending   0          0s    <none>       cluster1-worker          <none>           <none>
kube-system          kube-scheduler-cluster1-control-plane            1/1     Running   0          33s   172.18.0.3   cluster1-control-plane   <none>           <none>
local-path-storage   local-path-provisioner-5ddd94ff66-fgqmh          0/1     Pending   0          18s   <none>       <none>                   <none>           <none>

# install CNI
cilium install --context kind-cluster1 --version v1.12.0 --helm-set ipam.mode=kubernetes,cluster.name=cluster1,cluster.id=1
🔮 Auto-detected Kubernetes kind: kind
✨ Running "kind" validation checks
✅ Detected kind version "0.14.0"
ℹ️  Using Cilium version 1.12.0
🔮 Auto-detected cluster name: kind-cluster1
🔮 Auto-detected datapath mode: tunnel
ℹ️  helm template --namespace kube-system cilium cilium/cilium --version 1.12.0 --set cluster.id=1,cluster.name=cluster1,encryption.nodeEncryption=false,ipam.mode=kubernetes,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator,tunnel=vxlan
ℹ️  Storing helm values file in kube-system/cilium-cli-helm-values Secret
🔑 Created CA in secret cilium-ca
🔑 Generating certificates for Hubble...
🚀 Creating Service accounts...
🚀 Creating Cluster roles...
🚀 Creating ConfigMap for Cilium version 1.12.0...
🚀 Creating Agent DaemonSet...
🚀 Creating Operator Deployment...
⌛ Waiting for Cilium to be installed and ready...
✅ Cilium was successfully installed! Run 'cilium status' to view installation health
cilium status  --context kind-cluster1 --wait
[33m    /¯¯\
[36m /¯¯[33m\__/[32m¯¯\[0m    Cilium:         [32mOK[0m
[36m \__[31m/¯¯\[32m__/[0m    Operator:       [32mOK[0m
[32m /¯¯[31m\__/[35m¯¯\[0m    Hubble:         [36mdisabled[0m
[32m \__[34m/¯¯\[35m__/[0m    ClusterMesh:    [36mdisabled[0m
[34m    \__/
[0m
Deployment        cilium-operator    Desired: 1, Ready: [32m1/1[0m, Available: [32m1/1[0m
DaemonSet         cilium             Desired: 2, Ready: [32m2/2[0m, Available: [32m2/2[0m
Containers:       cilium             Running: [32m2[0m
                  cilium-operator    Running: [32m1[0m
Cluster Pods:     3/3 managed by Cilium
Image versions    cilium-operator    quay.io/cilium/operator-generic:v1.12.0@sha256:bb2a42eda766e5d4a87ee8a5433f089db81b72dd04acf6b59fcbb445a95f9410: 1
                  cilium             quay.io/cilium/cilium:v1.12.0@sha256:079baa4fa1b9fe638f96084f4e0297c84dd4fb215d29d2321dcbe54273f63ade: 2

